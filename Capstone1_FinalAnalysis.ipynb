{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 1 : Analysis, Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will apply ML techniques to the transcript and the features we extracted to predict the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functon for text normalization\n",
    "def text_preprocess(text):\n",
    "    # Strip leading and lagging whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Remove accented characters\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "    # Convert all text to lower case\n",
    "    text.lower()\n",
    "    \n",
    "    # Take raw text and remove all audience reactions\n",
    "    text = re.sub('\\((.*?)\\)', '', text)\n",
    "    \n",
    "    # Expand Contactions\n",
    "    # Specific\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    # general\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    \n",
    "    # Remove Punctuation\n",
    "    pattern = r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "#     # Remove punctuation\n",
    "#     normalized_text.translate( str.maketrans('','', string.punctuation))\n",
    "#     # Word tokenization\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     tokens = word_tokenize(normalized_text)\n",
    "#     result = [i for i in tokens if not i in stop_words]\n",
    "#     stemmer = PorterStemmer()\n",
    "#     stemmed_result = []\n",
    "#     for word in result:\n",
    "#         stemmed_result.append(stemmer.stem(word))\n",
    "#     return stemmed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data after statistical analysis\n",
    "df_clean = pd.read_csv(r'After_StatisticalAnalysis.csv', index_col = 0)\n",
    "df_clean.index.name = \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>film_datestamp</th>\n",
       "      <th>pub_datestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>Inspiring</th>\n",
       "      <th>event_type</th>\n",
       "      <th>Max_rating</th>\n",
       "      <th>ratings_total</th>\n",
       "      <th>word_per_min</th>\n",
       "      <th>tag_technology</th>\n",
       "      <th>tag_science</th>\n",
       "      <th>tag_global issues</th>\n",
       "      <th>tag_culture</th>\n",
       "      <th>tag_design</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['tag_children', 'tag_creativity', 'tag_cultur...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
       "      <td>2006-02-25 00:00:00</td>\n",
       "      <td>2006-06-27 00:11:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398474</td>\n",
       "      <td>TED</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>89411</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Climate advocate</td>\n",
       "      <td>['tag_alternative energy', 'tag_cars', 'tag_cl...</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>2006-02-25 00:00:00</td>\n",
       "      <td>2006-06-27 00:11:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241489</td>\n",
       "      <td>TED</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>2820</td>\n",
       "      <td>127</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  duration    event  \\\n",
       "index                                                                         \n",
       "0      Sir Ken Robinson makes an entertaining and pro...      1164  TED2006   \n",
       "1      With the same humor and humanity he exuded in ...       977  TED2006   \n",
       "\n",
       "       main_speaker speaker_occupation  \\\n",
       "index                                    \n",
       "0      Ken Robinson    Author/educator   \n",
       "1           Al Gore   Climate advocate   \n",
       "\n",
       "                                                    tags  \\\n",
       "index                                                      \n",
       "0      ['tag_children', 'tag_creativity', 'tag_cultur...   \n",
       "1      ['tag_alternative energy', 'tag_cars', 'tag_cl...   \n",
       "\n",
       "                             title  \\\n",
       "index                                \n",
       "0      Do schools kill creativity?   \n",
       "1      Averting the climate crisis   \n",
       "\n",
       "                                              transcript       film_datestamp  \\\n",
       "index                                                                           \n",
       "0      Good morning. How are you?(Laughter)It's been ...  2006-02-25 00:00:00   \n",
       "1      Thank you so much, Chris. And it's truly a gre...  2006-02-25 00:00:00   \n",
       "\n",
       "             pub_datestamp  ...  Inspiring  event_type  Max_rating  \\\n",
       "index                       ...                                      \n",
       "0      2006-06-27 00:11:00  ...   0.398474         TED   Inspiring   \n",
       "1      2006-06-27 00:11:00  ...   0.241489         TED   Inspiring   \n",
       "\n",
       "       ratings_total  word_per_min  tag_technology  tag_science  \\\n",
       "index                                                             \n",
       "0              89411           163           False        False   \n",
       "1               2820           127            True         True   \n",
       "\n",
       "       tag_global issues  tag_culture  tag_design  \n",
       "index                                              \n",
       "0                  False         True       False  \n",
       "1                   True         True       False  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['clean_transcript'] = df_clean.transcript.apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class mapping\n",
    "class_dict = ({'Inspiring': 1, 'Funny' : 2, 'Informative' : 3,'Ingenious' : 4, \n",
    "                 'Beautiful' : 5, 'Confusing' :6, 'Courageous':7, 'Fascinating' : 8, \n",
    "                'OK' :9 , 'Unconvincing' : 10})\n",
    "df_clean['MaxRating_Class'] =  df_clean.Max_rating.map(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>film_datestamp</th>\n",
       "      <th>pub_datestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>Max_rating</th>\n",
       "      <th>ratings_total</th>\n",
       "      <th>word_per_min</th>\n",
       "      <th>tag_technology</th>\n",
       "      <th>tag_science</th>\n",
       "      <th>tag_global issues</th>\n",
       "      <th>tag_culture</th>\n",
       "      <th>tag_design</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>MaxRating_Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['tag_children', 'tag_creativity', 'tag_cultur...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
       "      <td>2006-02-25 00:00:00</td>\n",
       "      <td>2006-06-27 00:11:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>89411</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Good morning  How are you It is been great  ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Climate advocate</td>\n",
       "      <td>['tag_alternative energy', 'tag_cars', 'tag_cl...</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>2006-02-25 00:00:00</td>\n",
       "      <td>2006-06-27 00:11:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>2820</td>\n",
       "      <td>127</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you so much  Chris  And it is truly a gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  duration    event  \\\n",
       "index                                                                         \n",
       "0      Sir Ken Robinson makes an entertaining and pro...      1164  TED2006   \n",
       "1      With the same humor and humanity he exuded in ...       977  TED2006   \n",
       "\n",
       "       main_speaker speaker_occupation  \\\n",
       "index                                    \n",
       "0      Ken Robinson    Author/educator   \n",
       "1           Al Gore   Climate advocate   \n",
       "\n",
       "                                                    tags  \\\n",
       "index                                                      \n",
       "0      ['tag_children', 'tag_creativity', 'tag_cultur...   \n",
       "1      ['tag_alternative energy', 'tag_cars', 'tag_cl...   \n",
       "\n",
       "                             title  \\\n",
       "index                                \n",
       "0      Do schools kill creativity?   \n",
       "1      Averting the climate crisis   \n",
       "\n",
       "                                              transcript       film_datestamp  \\\n",
       "index                                                                           \n",
       "0      Good morning. How are you?(Laughter)It's been ...  2006-02-25 00:00:00   \n",
       "1      Thank you so much, Chris. And it's truly a gre...  2006-02-25 00:00:00   \n",
       "\n",
       "             pub_datestamp  ...  Max_rating  ratings_total  word_per_min  \\\n",
       "index                       ...                                            \n",
       "0      2006-06-27 00:11:00  ...   Inspiring          89411           163   \n",
       "1      2006-06-27 00:11:00  ...   Inspiring           2820           127   \n",
       "\n",
       "       tag_technology  tag_science  tag_global issues  tag_culture  \\\n",
       "index                                                                \n",
       "0               False        False              False         True   \n",
       "1                True         True               True         True   \n",
       "\n",
       "       tag_design                                   clean_transcript  \\\n",
       "index                                                                  \n",
       "0           False  Good morning  How are you It is been great  ha...   \n",
       "1           False  Thank you so much  Chris  And it is truly a gr...   \n",
       "\n",
       "       MaxRating_Class  \n",
       "index                   \n",
       "0                    1  \n",
       "1                    1  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['description', 'duration', 'event', 'main_speaker',\n",
       "       'speaker_occupation', 'tags', 'title', 'transcript', 'film_datestamp',\n",
       "       'pub_datestamp', 'sentence_count', 'word_count', 'applause', 'laughter',\n",
       "       'music', 'cheering', 'sighs', 'singing', 'video', 'audio', 'Funny',\n",
       "       'Informative', 'Inspiring', 'event_type', 'Max_rating', 'ratings_total',\n",
       "       'word_per_min', 'tag_technology', 'tag_science', 'tag_global issues',\n",
       "       'tag_culture', 'tag_design', 'clean_transcript', 'MaxRating_Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best predictors(words) for each ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Factors and targets for NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_metadata = df_clean[['description', 'duration', 'event', 'main_speaker',\n",
    "       'speaker_occupation', 'title', 'transcript', 'sentence_count', 'word_count', 'applause', 'laughter',\n",
    "       'music', 'cheering', 'sighs', 'singing', 'video', 'audio', 'event_type', 'ratings_total',\n",
    "       'word_per_min', 'tag_technology', 'tag_science', 'tag_global issues',\n",
    "       'tag_culture', 'tag_design']]\n",
    "# X_transcript = df_clean[['transcript']]\n",
    "\n",
    "y_Funny = df_clean[['Funny']]\n",
    "y_Informative = df_clean[['Informative']]\n",
    "y_Inspiring = df_clean[['Inspiring']]\n",
    "y_MaxRating = df_clean[['MaxRating_Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words = {'english'}, min_df = 0.02, max_df = 0.95)\n",
    "vectorizer.fit(df_clean.clean_transcript)\n",
    "X_transcript = vectorizer.transform(df_clean.clean_transcript)\n",
    "# X_transcript = X_transcript.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2314, 4336)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transcript.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.95, max_features=None, min_df=0.02,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words={'english'},\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing\n",
    "Before training a naive Bayes Classifier to get best predictor words, we will perform text normalization on the transcripts. We will do the following\n",
    "1. Remove accented characters and special characters\n",
    "2. Remove comments and audience reactions in parenthesis\n",
    "2. Make all text lower cased\n",
    "3. Expand contractions\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score (training)is  0.8318196891413412\n",
      "Balanced accuracy score (test)is  0.7852494577006508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transcript, (y_MaxRating), test_size = 0.2)\n",
    "nb = MultinomialNB(alpha=100)\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score using balanced accuracy scores\n",
    "print ('Balanced accuracy score (training)is ', balanced_accuracy_score(nb.predict(X_train), y_train))\n",
    "print ('Balanced accuracy score (test)is ', balanced_accuracy_score(nb.predict(X_test), y_test))\n",
    "\n",
    "# print ('Accuracy of model on training set is ', nb.score(X_train, y_train))\n",
    "# print ('Accuracy of model on test set is ', nb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has large difference between training and test because the classes are severely unbalanced. However, we will not optimize it further at this point. Instead we will continue to use it for predicting words indicative of each rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score (test)is  0.7651236668935785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "# Train model with entire dataset\n",
    "nb = MultinomialNB(alpha = 100)\n",
    "nb.fit(X_transcript, y_MaxRating)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print ('Balanced accuracy score (test)is ', balanced_accuracy_score(nb.predict(X_transcript), y_MaxRating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find words indicative of each rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4336,)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.eye(X_transcript.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Inspiring': 1,\n",
       " 'Funny': 2,\n",
       " 'Informative': 3,\n",
       " 'Ingenious': 4,\n",
       " 'Beautiful': 5,\n",
       " 'Confusing': 6,\n",
       " 'Courageous': 7,\n",
       " 'Fascinating': 8,\n",
       " 'OK': 9,\n",
       " 'Unconvincing': 10}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each rating, w ecan find the words with highest probability and lowest probability for a particular rating. \n",
    "So, we will look at best and worst predictors of three ratings : Inspiring, Funny and Informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words\t     P(Inspiring | word)\n",
      "             neurons 0.75\n",
      "           telescope 0.73\n",
      "                 dna 0.72\n",
      "               genes 0.71\n",
      "             planets 0.71\n",
      "              genome 0.70\n",
      "               males 0.70\n",
      "             quantum 0.70\n",
      "           particles 0.69\n",
      "            magnetic 0.69\n",
      "              cortex 0.69\n",
      "            organism 0.69\n",
      "                 tag 0.69\n",
      "             imaging 0.69\n",
      "             mammals 0.68\n"
     ]
    }
   ],
   "source": [
    "# For 'Inspiring'\n",
    "probs_inspiring = nb.predict_log_proba(x)[:, 0]\n",
    "ind = np.argsort(probs_inspiring)\n",
    "\n",
    "good_words = words[ind[:15]]\n",
    "bad_words = words[ind[-15:]]\n",
    "\n",
    "good_prob = probs_inspiring[ind[:15]]\n",
    "bad_prob = probs_inspiring[ind[-15:]]\n",
    "\n",
    "print(\"Good words\\t     P(Inspiring | word)\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "    \n",
    "# print(\"Bad words\\t     P(Inspiring | word)\")\n",
    "# for w, p in zip(bad_words, bad_prob):\n",
    "#     print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words\t     P(Funny | word)\n",
      "                 our 0.99\n",
      "               world 0.99\n",
      "               their 0.99\n",
      "                  us 0.98\n",
      "                need 0.98\n",
      "              people 0.98\n",
      "               those 0.98\n",
      "             percent 0.98\n",
      "               years 0.98\n",
      "               these 0.98\n",
      "              change 0.98\n",
      "                most 0.98\n",
      "                many 0.98\n",
      "                been 0.98\n",
      "                more 0.98\n",
      "Bad words\t     P(Funny | word)\n",
      "               honey 0.90\n",
      "         advertising 0.90\n",
      "              emails 0.90\n",
      "                joke 0.90\n",
      "              dating 0.90\n",
      "                 dan 0.90\n",
      "                 huh 0.89\n",
      "             cartoon 0.89\n",
      "               males 0.89\n",
      "               hello 0.89\n",
      "               laugh 0.89\n",
      "                  hi 0.89\n",
      "            laughing 0.88\n",
      "               humor 0.87\n",
      "                flag 0.86\n"
     ]
    }
   ],
   "source": [
    "# For 'Funny'\n",
    "probs_funny = nb.predict_log_proba(x)[:, 1]\n",
    "ind = np.argsort(probs_funny)\n",
    "\n",
    "good_words = words[ind[:15]]\n",
    "bad_words = words[ind[-15:]]\n",
    "\n",
    "good_prob = probs_funny[ind[:15]]\n",
    "bad_prob = probs_funny[ind[-15:]]\n",
    "\n",
    "print(\"Good words\\t     P(Funny | word)\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "\n",
    "# print(\"Bad words\\t     P(Funny | word)\")\n",
    "# for w, p in zip(bad_words, bad_prob):\n",
    "#     print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words\t     P(Informative | word)\n",
      "                  my 0.92\n",
      "                 she 0.92\n",
      "              school 0.92\n",
      "                kids 0.91\n",
      "                  me 0.90\n",
      "               girls 0.90\n",
      "                 her 0.90\n",
      "                said 0.90\n",
      "                feel 0.90\n",
      "                 him 0.90\n",
      "          compassion 0.90\n",
      "              myself 0.90\n",
      "                felt 0.90\n",
      "                 god 0.89\n",
      "                love 0.89\n",
      "Bad words\t     P(Informative | word)\n",
      "               drugs 0.69\n",
      "             disease 0.69\n",
      "             privacy 0.69\n",
      "             planets 0.69\n",
      "               virus 0.68\n",
      "             genetic 0.68\n",
      "              genome 0.67\n",
      "                 flu 0.67\n",
      "                data 0.67\n",
      "             neurons 0.66\n",
      "                gene 0.66\n",
      "               sleep 0.65\n",
      "               brain 0.65\n",
      "                 dna 0.64\n",
      "               genes 0.62\n"
     ]
    }
   ],
   "source": [
    "# For 'Informative'\n",
    "probs_informative = nb.predict_log_proba(x)[:, 2]\n",
    "ind = np.argsort(probs_informative)\n",
    "\n",
    "good_words = words[ind[:15]]\n",
    "bad_words = words[ind[-15:]]\n",
    "\n",
    "good_prob = probs_informative[ind[:15]]\n",
    "bad_prob = probs_informative[ind[-15:]]\n",
    "\n",
    "print(\"Good words\\t     P(Informative | word)\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "    \n",
    "print(\"Bad words\\t     P(Informative | word)\")\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
