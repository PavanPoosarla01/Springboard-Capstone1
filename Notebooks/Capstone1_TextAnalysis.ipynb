{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 1 : Analysis, Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will apply ML techniques to the transcript and the features we extracted to predict the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Pavan\n",
      "[nltk_data]     Anirudh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Pavan\n",
      "[nltk_data]     Anirudh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Import NLP Modules\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functon for text normalization\n",
    "\n",
    "def text_preprocess(text):\n",
    "    # Strip leading and lagging whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Remove accented characters\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "    # Convert all text to lower case\n",
    "    text.lower()\n",
    "    \n",
    "    # Take raw text and remove all audience reactions\n",
    "    text = re.sub('\\((.*?)\\)', '', text)\n",
    "    \n",
    "    # Expand Contactions\n",
    "    # Specific\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    # general\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    \n",
    "    # Remove Punctuation\n",
    "    pattern = r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    \n",
    "#     # Word Lemmatization\n",
    "#     wnl = WordNetLemmatizer()\n",
    "    \n",
    "#     nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
    "#     text = nlp(text)\n",
    "#     text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "#     # Remove punctuation\n",
    "#     normalized_text.translate( str.maketrans('','', string.punctuation))\n",
    "#     # Word tokenization\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     tokens = word_tokenize(normalized_text)\n",
    "#     result = [i for i in tokens if not i in stop_words]\n",
    "#     stemmer = PorterStemmer()\n",
    "#     stemmed_result = []\n",
    "#     for word in result:\n",
    "#         stemmed_result.append(stemmer.stem(word))\n",
    "#     return stemmed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data after statistical analysis\n",
    "df_clean = pd.read_csv(r'../data/interim/After_StatisticalAnalysis.csv', index_col = 0)\n",
    "df_clean.index.name = \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>film_datestamp</th>\n",
       "      <th>pub_datestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>Max_rating</th>\n",
       "      <th>ratings_total</th>\n",
       "      <th>word_per_min</th>\n",
       "      <th>tag_technology</th>\n",
       "      <th>tag_science</th>\n",
       "      <th>tag_global issues</th>\n",
       "      <th>tag_culture</th>\n",
       "      <th>tag_design</th>\n",
       "      <th>tag_business</th>\n",
       "      <th>tag_entertainment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['tag_children', 'tag_creativity', 'tag_cultur...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
       "      <td>2006-02-25 00:00:00</td>\n",
       "      <td>2006-06-27 00:11:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Funny</td>\n",
       "      <td>49356</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Climate advocate</td>\n",
       "      <td>['tag_alternative energy', 'tag_cars', 'tag_cl...</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>2006-02-25 00:00:00</td>\n",
       "      <td>2006-06-27 00:11:00</td>\n",
       "      <td>...</td>\n",
       "      <td>BadTalk</td>\n",
       "      <td>1797</td>\n",
       "      <td>127</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  duration    event  \\\n",
       "index                                                                         \n",
       "0      Sir Ken Robinson makes an entertaining and pro...      1164  TED2006   \n",
       "1      With the same humor and humanity he exuded in ...       977  TED2006   \n",
       "\n",
       "       main_speaker speaker_occupation  \\\n",
       "index                                    \n",
       "0      Ken Robinson    Author/educator   \n",
       "1           Al Gore   Climate advocate   \n",
       "\n",
       "                                                    tags  \\\n",
       "index                                                      \n",
       "0      ['tag_children', 'tag_creativity', 'tag_cultur...   \n",
       "1      ['tag_alternative energy', 'tag_cars', 'tag_cl...   \n",
       "\n",
       "                             title  \\\n",
       "index                                \n",
       "0      Do schools kill creativity?   \n",
       "1      Averting the climate crisis   \n",
       "\n",
       "                                              transcript       film_datestamp  \\\n",
       "index                                                                           \n",
       "0      Good morning. How are you?(Laughter)It's been ...  2006-02-25 00:00:00   \n",
       "1      Thank you so much, Chris. And it's truly a gre...  2006-02-25 00:00:00   \n",
       "\n",
       "             pub_datestamp  ...  Max_rating  ratings_total  word_per_min  \\\n",
       "index                       ...                                            \n",
       "0      2006-06-27 00:11:00  ...       Funny          49356           163   \n",
       "1      2006-06-27 00:11:00  ...     BadTalk           1797           127   \n",
       "\n",
       "       tag_technology  tag_science  tag_global issues  tag_culture  \\\n",
       "index                                                                \n",
       "0               False        False              False         True   \n",
       "1                True         True               True         True   \n",
       "\n",
       "       tag_design  tag_business  tag_entertainment  \n",
       "index                                               \n",
       "0           False         False              False  \n",
       "1           False         False              False  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing\n",
    "Before training a naive Bayes Classifier to get best predictor words, we will perform text normalization on the transcripts. We will do the following\n",
    "1. Remove accented characters and special characters\n",
    "2. Remove comments and audience reactions in parenthesis\n",
    "2. Make all text lower cased\n",
    "3. Expand contractions\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['clean_transcript'] = df_clean.transcript.apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class mapping\n",
    "class_dict = ({'Fascinating': 1, 'BadTalk': 2, 'Beautiful':3,'Informative':4, 'Funny':5})\n",
    "\n",
    "# class_dict = ({'Inspiring': 1, 'Funny' : 2, 'Informative' : 3,'Ingenious' : 4, \n",
    "#                  'Beautiful' : 5, 'Confusing' :6, 'Courageous':7, 'Fascinating' : 8, \n",
    "#                 'OK' :9 , 'Unconvincing' : 10})\n",
    "df_clean['MaxRating_Class'] =  df_clean.Max_rating.map(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Max_rating\n",
       "BadTalk        163\n",
       "Beautiful      296\n",
       "Fascinating    880\n",
       "Funny          154\n",
       "Informative    821\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.groupby(['Max_rating']).count().title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>film_datestamp</th>\n",
       "      <th>pub_datestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>word_per_min</th>\n",
       "      <th>tag_technology</th>\n",
       "      <th>tag_science</th>\n",
       "      <th>tag_global issues</th>\n",
       "      <th>tag_culture</th>\n",
       "      <th>tag_design</th>\n",
       "      <th>tag_business</th>\n",
       "      <th>tag_entertainment</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>MaxRating_Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['tag_children', 'tag_creativity', 'tag_cultur...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
       "      <td>2006-02-25 00:00:00</td>\n",
       "      <td>2006-06-27 00:11:00</td>\n",
       "      <td>...</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Good morning  How are you It is been great  ha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Climate advocate</td>\n",
       "      <td>['tag_alternative energy', 'tag_cars', 'tag_cl...</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>2006-02-25 00:00:00</td>\n",
       "      <td>2006-06-27 00:11:00</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you so much  Chris  And it is truly a gr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  duration    event  \\\n",
       "index                                                                         \n",
       "0      Sir Ken Robinson makes an entertaining and pro...      1164  TED2006   \n",
       "1      With the same humor and humanity he exuded in ...       977  TED2006   \n",
       "\n",
       "       main_speaker speaker_occupation  \\\n",
       "index                                    \n",
       "0      Ken Robinson    Author/educator   \n",
       "1           Al Gore   Climate advocate   \n",
       "\n",
       "                                                    tags  \\\n",
       "index                                                      \n",
       "0      ['tag_children', 'tag_creativity', 'tag_cultur...   \n",
       "1      ['tag_alternative energy', 'tag_cars', 'tag_cl...   \n",
       "\n",
       "                             title  \\\n",
       "index                                \n",
       "0      Do schools kill creativity?   \n",
       "1      Averting the climate crisis   \n",
       "\n",
       "                                              transcript       film_datestamp  \\\n",
       "index                                                                           \n",
       "0      Good morning. How are you?(Laughter)It's been ...  2006-02-25 00:00:00   \n",
       "1      Thank you so much, Chris. And it's truly a gre...  2006-02-25 00:00:00   \n",
       "\n",
       "             pub_datestamp  ...  word_per_min  tag_technology  tag_science  \\\n",
       "index                       ...                                              \n",
       "0      2006-06-27 00:11:00  ...           163           False        False   \n",
       "1      2006-06-27 00:11:00  ...           127            True         True   \n",
       "\n",
       "       tag_global issues  tag_culture  tag_design  tag_business  \\\n",
       "index                                                             \n",
       "0                  False         True       False         False   \n",
       "1                   True         True       False         False   \n",
       "\n",
       "       tag_entertainment                                   clean_transcript  \\\n",
       "index                                                                         \n",
       "0                  False  Good morning  How are you It is been great  ha...   \n",
       "1                  False  Thank you so much  Chris  And it is truly a gr...   \n",
       "\n",
       "       MaxRating_Class  \n",
       "index                   \n",
       "0                    5  \n",
       "1                    2  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['description', 'duration', 'event', 'main_speaker',\n",
       "       'speaker_occupation', 'tags', 'title', 'transcript', 'film_datestamp',\n",
       "       'pub_datestamp', 'sentence_count', 'word_count', 'applause', 'laughter',\n",
       "       'music', 'cheering', 'sighs', 'singing', 'video', 'audio', 'Funny',\n",
       "       'Beautiful', 'Informative', 'Fascinating', 'Inspiring', 'event_type',\n",
       "       'BadTalk', 'Max_rating', 'ratings_total', 'word_per_min',\n",
       "       'tag_technology', 'tag_science', 'tag_global issues', 'tag_culture',\n",
       "       'tag_design', 'tag_business', 'tag_entertainment', 'clean_transcript',\n",
       "       'MaxRating_Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Dataset used for modelling to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('../data/processed/DataforModelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2314, 39)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best predictors(words) for each ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to analyse the transcripts to see which words will be strongly predictive of each of the ratings. We do this by training a Naive Bayes classifier by only considering the transcripts.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Factors and targets for NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_transcript = df_clean[['transcript']]\n",
    "\n",
    "y_Funny = df_clean[['Funny']]\n",
    "y_Informative = df_clean[['Informative']]\n",
    "y_Inspiring = df_clean[['Inspiring']]\n",
    "y_MaxRating = df_clean[['MaxRating_Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words = stopwords.words('english'), min_df = 2, max_df = 0.98)\n",
    "vectorizer.fit(df_clean.clean_transcript)\n",
    "X_transcript = vectorizer.transform(df_clean.clean_transcript)\n",
    "# X_transcript = X_transcript.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2314, 32665)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transcript.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.98, max_features=None, min_df=2,\n",
       "                ngram_range=(1, 1), preprocessor=None,\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score (training)is  0.6169049959546393\n",
      "Balanced accuracy score (test)is  0.5805830459898795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transcript, (y_MaxRating), test_size = 0.2)\n",
    "nb = MultinomialNB(alpha=100)\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score using balanced accuracy scores\n",
    "print ('Balanced accuracy score (training)is ', balanced_accuracy_score(nb.predict(X_train), y_train))\n",
    "print ('Balanced accuracy score (test)is ', balanced_accuracy_score(nb.predict(X_test), y_test))\n",
    "\n",
    "# print ('Accuracy of model on training set is ', nb.score(X_train, y_train))\n",
    "# print ('Accuracy of model on test set is ', nb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has large difference between training and test because the classes are severely unbalanced. However, we will not optimize it further at this point. Instead we will continue to use it for predicting words indicative of each rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score (test)is  0.6118445746434003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "# Train model with entire dataset\n",
    "nb = MultinomialNB(alpha = 100)\n",
    "nb.fit(X_transcript, y_MaxRating)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print ('Balanced accuracy score (test)is ', balanced_accuracy_score(nb.predict(X_transcript), y_MaxRating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model with TF-IDF vectorizer instaed of CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer(stop_words = stopwords.words('english'), min_df = 2, max_df = 0.98, use_idf = True)\n",
    "tfidf_vec.fit(df_clean.clean_transcript)\n",
    "X_transcript_tfidf = tfidf_vec.transform(df_clean.clean_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score (training)is  0.6914316702819957\n",
      "Balanced accuracy score (test)is  0.6406349206349207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes on this now\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_transcript_tfidf, (y_MaxRating), test_size = 0.2)\n",
    "nb2 = MultinomialNB(alpha=100)\n",
    "nb2.fit(X_train2, y_train2)\n",
    "y_pred2 = nb.predict(X_test2)\n",
    "\n",
    "# Calculate accuracy score using balanced accuracy scores\n",
    "print ('Balanced accuracy score (training)is ', balanced_accuracy_score(nb2.predict(X_train2), y_train2))\n",
    "print ('Balanced accuracy score (test)is ', balanced_accuracy_score(nb.predict(X_test2), y_test2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we can get much better results on Naive Bayes using TF-IDF vectorization instaed of count vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find words indicative of each rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32665,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.eye(X_transcript.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fascinating': 1, 'BadTalk': 2, 'Beautiful': 3, 'Informative': 4, 'Funny': 5}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each rating, we can find the words with highest probability and lowest probability for a particular rating. \n",
    "So, we will look at best and worst predictors of three ratings : Inspiring, Funny and Informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words\t     P(Fascinating | word)\n",
      "              device 0.61\n",
      "               space 0.62\n",
      "             objects 0.62\n",
      "                cell 0.62\n",
      "               brain 0.62\n",
      "           structure 0.63\n",
      "              object 0.63\n",
      "                 fly 0.63\n",
      "            computer 0.64\n",
      "                 dna 0.64\n",
      "               light 0.65\n",
      "              robots 0.65\n",
      "            universe 0.68\n",
      "               cells 0.68\n",
      "               robot 0.74\n",
      "Bad words\t     P(Fascinating | word)\n",
      "               women 0.18\n",
      "         governments 0.23\n",
      "              rights 0.23\n",
      "              sector 0.24\n",
      "            refugees 0.25\n",
      "           democracy 0.25\n",
      "               girls 0.25\n",
      "           societies 0.25\n",
      "                 men 0.26\n",
      "           political 0.26\n",
      "              global 0.26\n",
      "          inequality 0.26\n",
      "               civil 0.26\n",
      "             country 0.26\n",
      "        institutions 0.26\n"
     ]
    }
   ],
   "source": [
    "# For 'Fascinating'\n",
    "probs_fascinating = nb.predict_proba(x)[:, 0]\n",
    "ind = np.argsort(probs_fascinating)\n",
    "\n",
    "good_words = words[ind[-15:]]\n",
    "bad_words = words[ind[:15]]\n",
    "\n",
    "good_prob = probs_fascinating[ind[-15:]]\n",
    "bad_prob = probs_fascinating[ind[:15]]\n",
    "\n",
    "print(\"Good words\\t     P(Fascinating | word)\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(p))\n",
    "    \n",
    "print(\"Bad words\\t     P(Fascinating | word)\")\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words\t     P(Fascinating | word)\n",
      "               light 0.65\n",
      "              robots 0.65\n",
      "            universe 0.68\n",
      "               cells 0.68\n",
      "               robot 0.74\n",
      "Bad words\t     P(Fascinating | word)\n",
      "               women 0.18\n",
      "         governments 0.23\n",
      "              rights 0.23\n",
      "              sector 0.24\n",
      "            refugees 0.25\n",
      "Good words\t     P(BadTalk | word)\n",
      "                 god 0.10\n",
      "              tapirs 0.10\n",
      "          concussion 0.11\n",
      "           glamorous 0.11\n",
      "             glamour 0.12\n",
      "Bad words\t     P(BadTalk | word)\n",
      "                data 0.02\n",
      "               brain 0.02\n",
      "                 two 0.02\n",
      "               cells 0.02\n",
      "                 see 0.02\n",
      "Good words\t     P(Beautiful | word)\n",
      "                song 0.21\n",
      "                girl 0.21\n",
      "              poetry 0.22\n",
      "          compassion 0.22\n",
      "                 hum 0.22\n",
      "Bad words\t     P(Beautiful | word)\n",
      "                data 0.02\n",
      "         information 0.03\n",
      "             percent 0.03\n",
      "               brain 0.03\n",
      "          technology 0.03\n",
      "Good words\t     P(Informative | word)\n",
      "             country 0.61\n",
      "          government 0.62\n",
      "           companies 0.62\n",
      "               women 0.63\n",
      "              global 0.64\n",
      "Bad words\t     P(Informative | word)\n",
      "               robot 0.16\n",
      "            universe 0.21\n",
      "                 art 0.22\n",
      "              object 0.22\n",
      "              robots 0.22\n",
      "Good words\t     P(Funny | word)\n",
      "               humor 0.11\n",
      "              comedy 0.11\n",
      "                flag 0.11\n",
      "            laughter 0.11\n",
      "                  dh 0.13\n",
      "Bad words\t     P(Funny | word)\n",
      "             percent 0.01\n",
      "               world 0.01\n",
      "               years 0.01\n",
      "                  us 0.01\n",
      "               human 0.01\n"
     ]
    }
   ],
   "source": [
    "# Write a loop to get best and worset predictive words for all classes\n",
    "probs_dict = {}\n",
    "for rating in class_dict.keys():\n",
    "    probs_dict[rating+'_probs'] = nb.predict_proba(x)[:, class_dict[rating]-1]\n",
    "    ind = np.argsort(probs_dict[rating+'_probs'])\n",
    "    # Get good and bad words\n",
    "    good_words = words[ind[-5:]]\n",
    "    bad_words = words[ind[:5]]\n",
    "    # Get corresponding probabilities\n",
    "    good_prob = probs_dict[rating+'_probs'][ind[-5:]]\n",
    "    bad_prob = probs_dict[rating+'_probs'][ind[:5]]\n",
    "    \n",
    "    # Print Best and Worst predictive words\n",
    "    print(\"Good words\\t     P(%s | word)\" %rating)\n",
    "    for w, p in zip(good_words, good_prob):\n",
    "        print(\"{:>20}\".format(w), \"{:.2f}\".format(p))\n",
    "    \n",
    "    print(\"Bad words\\t     P(%s | word)\" %rating)\n",
    "    for w, p in zip(bad_words, bad_prob):\n",
    "        print(\"{:>20}\".format(w), \"{:.2f}\".format(p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, we can reasonably predict the class of the popular rating based on the words appearing in the transcript. \n",
    "In the next notebook on modelling, we will attempt to develop machine learning models to predict the most popular rating for each talk based on the metadata and the transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
